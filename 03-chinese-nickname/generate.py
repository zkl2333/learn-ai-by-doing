import torch
import torch.nn as nn
import torch.nn.functional as F
import random
import json
from config import *

# ========== æ¨¡å‹å®šä¹‰ ==========
class NicknameRNN(nn.Module):
    def __init__(self, vocab_size, hidden_size=HIDDEN_SIZE, embedding_dim=EMBEDDING_DIM):
        super().__init__()
        self.embed = nn.Embedding(vocab_size, embedding_dim)
        self.rnn = nn.GRU(embedding_dim, hidden_size, batch_first=True)
        self.fc = nn.Linear(hidden_size, vocab_size)
        self.hidden_size = hidden_size

    def forward(self, x, h=None):
        x = self.embed(x)
        out, h = self.rnn(x, h)
        out = self.fc(out)
        return out, h

# ========== åŠ è½½æ¨¡å‹ ==========
print(f"ğŸ“‚ åŠ è½½æ¨¡å‹: {MODEL_PATH}")
checkpoint = torch.load(MODEL_PATH, map_location=DEVICE, weights_only=False)

vocab_size = checkpoint['vocab_size']
hidden_size = checkpoint['hidden_size']
stoi = checkpoint['stoi']
itos = checkpoint['itos']

model = NicknameRNN(vocab_size, hidden_size=hidden_size).to(DEVICE)
model.load_state_dict(checkpoint['model_state_dict'])
model.eval()

print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
print(f"   - è¯å…¸å¤§å°: {vocab_size}")
print(f"   - éšè—å±‚å¤§å°: {hidden_size}")
print()

# ========== ç”Ÿæˆå‡½æ•° ==========
def generate(model, start="å°", max_len=MAX_GEN_LEN, temperature=TEMPERATURE):
    """
    ç”Ÿæˆæ˜µç§°

    å‚æ•°:
        model: è®­ç»ƒå¥½çš„æ¨¡å‹
        start: èµ·å§‹å­—ç¬¦
        max_len: æœ€å¤§ç”Ÿæˆé•¿åº¦
        temperature: æ¸©åº¦å‚æ•°ï¼Œè¶Šé«˜è¶Šéšæœº

    è¿”å›:
        ç”Ÿæˆçš„æ˜µç§°å­—ç¬¦ä¸²
    """
    model.eval()

    # ç¼–ç èµ·å§‹å­—ç¬¦
    input_ids = torch.tensor([[stoi.get(ch, 0) for ch in start]], dtype=torch.long, device=DEVICE)
    hidden = None
    result = list(start)

    with torch.no_grad():
        for _ in range(max_len):
            output, hidden = model(input_ids, hidden)
            logits = output[:, -1, :] / temperature
            probs = F.softmax(logits, dim=-1).squeeze()
            idx = torch.multinomial(probs, 1).item()
            ch = itos[idx]

            result.append(ch)

            # é‡åˆ°æ¢è¡Œç¬¦åœæ­¢
            if ch == "\n":
                break

            input_ids = torch.tensor([[idx]], dtype=torch.long, device=DEVICE)

    return "".join(result).strip()

# ========== ç”Ÿæˆç¤ºä¾‹ ==========
print("âœ¨ ç¤ºä¾‹ç”Ÿæˆæ˜µç§°ï¼š")
print("=" * 60)

# å¸¸è§èµ·å§‹å­—
start_chars = ["å°", "å–µ", "æ˜Ÿ", "æ¢¦", "å­¤", "æŸš", "é£", "ç³–", "å‘†", "è½¯"]

for _ in range(15):
    start = random.choice(start_chars)
    nickname = generate(model, start=start)
    print(f"ğŸ‘‰ {nickname}")

print("=" * 60)
print()

# ========== è‡ªå®šä¹‰ç”Ÿæˆ ==========
print("ğŸ’¡ æç¤º: è¾“å…¥ 'q' æˆ– 'quit' é€€å‡º")
print()

while True:
    try:
        user_input = input("è¯·è¾“å…¥èµ·å§‹å­—ç¬¦ï¼ˆé»˜è®¤éšæœºï¼‰: ").strip()

        if user_input.lower() in ['q', 'quit', 'exit']:
            print("ğŸ‘‹ å†è§ï¼")
            break

        if not user_input:
            user_input = random.choice(start_chars)

        # ç”Ÿæˆå¤šä¸ªæ ·æœ¬
        print(f"\nä»¥ '{user_input}' å¼€å¤´çš„æ˜µç§°ï¼š")
        for i in range(5):
            nickname = generate(model, start=user_input)
            print(f"  {i+1}. {nickname}")
        print()

    except KeyboardInterrupt:
        print("\nğŸ‘‹ å†è§ï¼")
        break
    except Exception as e:
        print(f"âŒ å‘ç”Ÿé”™è¯¯: {e}")
        print()