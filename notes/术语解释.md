# AI 学习术语解释

这份文档整理了学习 AI 过程中遇到的专业名词，用通俗的语言解释。

---

## 机器学习基础

### 逻辑回归 (Logistic Regression)

**是什么**：一种简单的分类算法，用来预测"是"或"否"这样的二分类问题。

**通俗理解**：虽然叫"回归"，但其实是做分类的。就像考试打分，模型给每个答案打分，超过及格线就判定为"是"。

**举例**：判断一个词是不是水果，模型会根据字符特征给它打分，超过阈值就判定为水果。

---

### 训练集 (Training Set) 和 测试集 (Test Set)

**是什么**：把数据分成两部分，一部分用来训练模型，一部分用来测试效果。

**为什么要分**：
- 训练集 = 课本和作业（用来学习）
- 测试集 = 考试试卷（用来检验真实水平）
- 如果用同一批数据训练和测试，就像考试考的都是作业原题，分数虚高

**典型比例**：80% 训练，20% 测试

---

### 验证集 (Validation Set)

**是什么**：从训练集中再分出一小部分，用来调整模型参数。

**三者关系**：
- 训练集 = 课本（用来学习知识）
- 验证集 = 模拟考（用来调整学习方法）
- 测试集 = 正式考试（最终评估）

---

## 特征工程

### 特征 (Feature)

**是什么**：机器能理解的"数字化信息"。

**通俗理解**：机器看不懂"苹果"这两个字，需要把文字转成数字，这些数字就是"特征"。

**举例**：
- "苹果" → 可能变成 [0, 1, 0, 1, 0...] 这样的数字列表
- 每个数字代表某个字符是否出现

---

### n-gram

**是什么**：把文本拆成连续的 n 个字符（或词）的组合。

**举例**：
- "苹果" 的 1-gram：["苹", "果"]
- "苹果" 的 2-gram：["苹果"]
- "草莓酱" 的 3-gram：["草莓酱"]

**为什么有用**：单个字符信息太少（"果"既可能是水果，也可能是"果然"），组合更有意义。

---

### 字符级 (Character-level)

**是什么**：把文本按单个字符拆分处理。

**举例**：
- 字符级："苹果汁" → ["苹", "果", "汁"]
- 词级："苹果汁很好喝" → ["苹果汁", "很", "好喝"]（需要分词）

**优势**：中文不需要分词，处理更简单。

---

### 字符嵌入 (Character Embedding)

**是什么**：把字符转换成数字向量（一串数字）。

**通俗理解**：
- 字符"苹"本身没有数学意义
- 嵌入层把它变成 [0.2, -0.5, 0.8, ...] 这样的向量
- 相似的字符会有相似的向量

---

## 模型评估

### 准确率 (Accuracy)

**是什么**：预测对的占总数的比例。

**公式**：准确率 = 预测对的数量 / 总数量

**举例**：100 个样本，预测对 80 个，准确率 = 80%

**局限性**：如果数据不平衡，准确率会误导人（见"类别不平衡"）

---

### 混淆矩阵 (Confusion Matrix)

**是什么**：一个表格，详细展示模型预测对错的情况。

**怎么看**：
```
                预测结果
          非水果    水果
实际 非水果   36      3    ← 36个预测对，3个误判为水果
     水果    10      16   ← 10个漏判，16个预测对
```

**能看出什么**：对角线是预测对的，其他格子是预测错的，还能看出是怎么错的。

---

### 精确率 (Precision)

**是什么**：在所有预测为"是"的里面，真正是"是"的比例。

**通俗理解**：我说是水果的，有多少真是水果？

**公式**：精确率 = 真阳性 / (真阳性 + 假阳性)

**举例**：模型说 19 个是水果（16 个真是 + 3 个误判），精确率 = 16/19 = 84%

---

### 召回率 (Recall)

**是什么**：在所有真实为"是"的里面，被预测出来的比例。

**通俗理解**：100 个水果，我找出了多少个？

**公式**：召回率 = 真阳性 / (真阳性 + 假阴性)

**举例**：实际有 26 个水果（16 个预测对 + 10 个漏判），召回率 = 16/26 = 62%

---

### F1 分数 (F1 Score)

**是什么**：精确率和召回率的综合评分。

**公式**：F1 = 2 × (精确率 × 召回率) / (精确率 + 召回率)

**为什么需要**：精确率和召回率通常此消彼长，F1 分数平衡两者，给出综合指标。

---

## 深度学习

### CNN (Convolutional Neural Network)

**全称**：卷积神经网络

**是什么**：一种善于提取模式的神经网络，最初用于图像识别，也可以用于文本。

**通俗理解**：用不同的"扫描窗口"扫描数据，自动学习有用的模式和特征。

**字符级 CNN**：把 CNN 用在文本上，一个字符一个字符地扫描。

---

### 卷积核 (Kernel)

**是什么**：CNN 中用来提取特征的"扫描窗口"。

**通俗理解**：
- 就像用不同大小的放大镜看文本
- kernel_size=2：每次看 2 个字符（如"苹果"）
- kernel_size=3：每次看 3 个字符（如"苹果汁"）

**多尺度卷积**：同时用多个不同大小的卷积核，捕获不同长度的模式。

---

### 池化 (Pooling)

**是什么**：提取最重要的信息，压缩数据。

**最大池化 (Max Pooling)**：在一堆数字里选最大的，相当于"这段文本最重要的特征是什么？"

---

### Dropout

**是什么**：训练时随机"关闭"一部分神经元，防止过拟合。

**通俗理解**：就像考试前不要只看同一本资料，随机遮住一部分信息，强迫模型学得更全面。

**举例**：`dropout=0.5` 表示随机关闭 50% 的神经元。

---

### 学习率 (Learning Rate)

**是什么**：模型每次调整参数的"步子"大小。

**通俗理解**：
- 学习率太大：跑得快，但可能跑过头
- 学习率太小：跑得慢，可能陷入局部最优

**典型值**：0.001, 0.01, 0.0001

---

### 批次大小 (Batch Size)

**是什么**：每次训练用多少条数据。

**举例**：
- 总共 800 条数据
- batch_size=32：每次喂 32 条给模型
- 需要 800/32 = 25 次才能过完所有数据

---

### 轮次 (Epoch)

**是什么**：所有训练数据过一遍模型，叫一个 epoch。

**举例**：800 条数据，训练 10 个 epoch，相当于把这 800 条数据让模型学 10 遍。

---

## 常见问题

### 过拟合 (Overfitting)

**是什么**：模型把训练数据"背"下来了，但没学会真正的规律。

**症状**：
- 训练准确率很高（比如 100%）
- 测试准确率很低（比如 76%）
- 差距很大

**通俗理解**：就像考试前把答案背下来，换个题目就不会了。

**解决办法**：
- 增加数据
- 降低模型复杂度
- 加正则化
- 用 Dropout

---

### 欠拟合 (Underfitting)

**是什么**：模型太简单，连训练数据都学不好。

**症状**：训练准确率低，测试准确率也低，两者都不好。

**解决办法**：
- 增加模型复杂度
- 训练更多轮
- 添加更多特征

---

### 类别不平衡 (Class Imbalance)

**是什么**：数据中不同类别的样本数量差异很大。

**举例**：
- 100 条数据：20 个水果，80 个非水果
- 模型可能学会"不确定就猜非水果"
- 准确率 80%，但实际上水果一个没认出来

**解决办法**：
- 使用 `class_weight='balanced'`
- 不要只看准确率，要看混淆矩阵
- 关注 F1 分数

---

### 数据泄露 (Data Leakage)

**是什么**：测试集的信息"泄露"到了训练过程中，导致测试结果虚高。

**常见错误**：
```python
# ❌ 错误：先转换再分割
X = vectorizer.fit_transform(all_data)  # 用了全部数据
X_train, X_test = split(X)

# ✅ 正确：先分割再转换
X_train_text, X_test_text = split(all_data)
X_train = vectorizer.fit_transform(X_train_text)  # 只用训练集
X_test = vectorizer.transform(X_test_text)
```

**为什么重要**：就像考试前偷看了考题，分数虚高，模型上线后效果差。

---

### 正则化 (Regularization)

**是什么**：限制模型复杂度，防止过拟合。

**通俗理解**：不让模型学得太"细致"，保留主要规律，忽略噪声。

---

### 超参数 (Hyperparameter)

**是什么**：训练前需要人为设定的参数（不是模型自己学的）。

**常见超参数**：
- 学习率
- 批次大小
- 模型层数
- Dropout 比例
- 正则化强度

**怎么调**：网格搜索、随机搜索等方法尝试不同组合。

---

## 工具和库

### sklearn (scikit-learn)

**是什么**：Python 里最常用的传统机器学习库。

**包含什么**：各种机器学习算法（逻辑回归、决策树等）、数据处理工具、评估指标等。

---

### PyTorch

**是什么**：深度学习框架，用来搭建和训练神经网络。

**特点**：代码直观、容易调试、学术界主流。

---

## 学习建议

### 不要死磕理论

很多术语第一次看不懂很正常，**实际用过就理解了**。

**建议**：
- 先有个大概印象
- 在项目中遇到时再回来查
- 多做几次就熟了

---

### 从小项目开始

不要一上来就做复杂任务，从判断水果这种简单任务开始：
- 能快速看到效果
- 流程简单，容易掌握
- 出错了容易排查

---

### 重视失败的实验

**失败的实验更有价值**：
- CNN 失败了，但学到了"深度学习不是万能"
- 过拟合了，但学到了数据量的重要性
- 调参没效果，但学到了模型选择的重要性

---

_更新时间：2025-10-16_
