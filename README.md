# Learn AI by Doing

从零开始学习 AI，用实际项目记录学习过程。

## 学习路线

每个项目都是独立的，从简单到复杂，循序渐进。所有项目都边做边学。

## 项目列表

### ✅ 01. 水果分类器

**完成时间**: 2025-10-16

**项目简介**: 判断一个中文词语是不是水果的二分类器

**技术栈**:
- 逻辑回归（Logistic Regression）
- 字符级特征提取（n-gram）
- sklearn

**数据规模**: 323 条（129 水果 + 194 非水果）

**最终效果**:
- 训练集准确率: 98.84%
- 验证集准确率: 80.00%
- 精确率: 84% | 召回率: 62%

**学到的东西**:
- 完整的机器学习流程（数据准备 → 特征提取 → 训练 → 评估）
- 过拟合问题的识别和解决
- 类别不平衡的处理（class_weight）
- 数据泄露的预防
- 混淆矩阵的理解和应用
- 评估指标的含义（Precision、Recall、F1）

**踩过的坑**:
- 数据太少导致过拟合
- 类别不平衡导致模型偏向多数类
- 差点先做特征提取再划分数据集

👉 [查看详情](./01-fruit-classifier/)

---

### ✅ 02. 水果分类器 - 字符级 CNN 版

**完成时间**: 2025-10-16

**项目简介**: 使用字符级卷积神经网络（CNN）升级第一个项目，从传统机器学习迈向深度学习

**技术栈**:
- 字符级卷积神经网络（Char-level CNN）
- 字符嵌入（Character Embedding）
- 多尺度卷积（Multi-scale Convolution）
- PyTorch

**数据规模**: 1051 条（365 水果 + 686 非水果）

**最终效果**:
- CNN验证准确率: 59.24%
- 逻辑回归验证准确率: **86.26%** ✨
- **结论**: 逻辑回归全面领先，CNN不适合此任务

**4次迭代过程**:
1. 迭代1(323条): CNN 69% vs LR 80%
2. 迭代2(826条): CNN 66% vs LR 81%
3. 迭代3(调参): CNN 67% vs LR 81%
4. 迭代4(1051条): CNN 59% vs LR 86% ❌

**学到的东西**:
- 深度学习基础概念（嵌入、卷积、池化）
- PyTorch 框架使用
- 字符级文本处理
- 训练过程监控和可视化
- 防止过拟合的技巧（Dropout、类别权重）
- 模型保存与加载
- 超参数调优方法
- 数据标注的重要性（植物学分类 vs 日常分类）
- **小数据集上深度学习的局限性**
- **模型选择比技术先进更重要**

**核心收获**:
> **并非所有问题都需要深度学习，选择合适的工具才是关键！**

虽然CNN失败了，但收获了:
- ✅ 完整的PyTorch实践经验
- ✅ 深刻理解不同模型的适用场景
- ✅ 打破"深度学习万能"的迷思
- ✅ 建立"具体问题具体分析"的思维
- ✅ 学会通过实验验证假设

**如果一开始就选逻辑回归，虽然效果好，但不会有这些深刻的认知。**

**踩过的坑**:
- 深度学习效果不如传统ML（数据量太小）
- 水果定义不清导致标注混乱
- 数据扩充后需重新检查标注一致性
- 调参收益极小，说明遇到了模型上限
- 学术名词让CNN字符模式学习失效

**与项目01对比**:
- 模型：逻辑回归 → CNN
- 特征：手工设计 → 自动学习
- 框架：sklearn → PyTorch
- 深度：传统ML → 深度学习入门
- **效果**: 86.26% vs 59.24% (逻辑回归完胜)

👉 [查看详情](./02-fruit-classifier-cnn/)

---

## 学习笔记

记录学习过程中的一些理解和总结。

（待添加）

---

## 关于我

一个 AI 初学者，通过动手做项目来学习机器学习。

选择这种学习方式的原因：
- 光看理论记不住，得动手做
- 从简单项目开始，快速获得成就感
- 用 Claude Code 边做边学，效率更高

---

## 技术栈

- Python 3.9+
- scikit-learn
- PyTorch
- pandas
- matplotlib
- Claude Code

---

## License

MIT