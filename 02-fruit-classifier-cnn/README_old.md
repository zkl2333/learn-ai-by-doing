# 02. 水果分类器 - 字符级 CNN 版

使用字符级卷积神经网络（Character-level CNN）判断中文词语是否为水果。

## 项目简介

这是第一个水果分类器的升级版本，从传统机器学习（逻辑回归）升级到深度学习（CNN）。

### 为什么使用字符级 CNN？

1. **适合中文短文本**：水果名通常只有 2-4 个字，字符级特征更有效
2. **捕捉字符模式**：能学习到"莓"、"果"、"瓜"等常见水果字符
3. **不需要分词**：直接处理字符序列，避免分词错误
4. **比逻辑回归更强**：多层网络能学习更复杂的特征组合

## 技术栈

- **PyTorch**: 深度学习框架
- **字符嵌入（Character Embedding）**: 将字符转换为向量
- **1D 卷积（Conv1D）**: 提取字符序列的局部特征
- **多尺度卷积核**: 使用 2-gram、3-gram、4-gram 同时捕捉不同长度的模式
- **最大池化（Max Pooling）**: 提取最重要的特征
- **全连接层**: 最终分类

## 模型架构

```
输入: "草莓" (字符序列)
  ↓
字符嵌入层 (Embedding)
  ↓
┌──────────┬──────────┬──────────┐
│  Conv1D  │  Conv1D  │  Conv1D  │
│ (k=2)    │ (k=3)    │ (k=4)    │  ← 多尺度卷积
└──────────┴──────────┴──────────┘
  ↓         ↓         ↓
MaxPool   MaxPool   MaxPool
  ↓         ↓         ↓
└─────────┬┴──────────┘
          ↓
    拼接特征 (Concat)
          ↓
      Dropout (0.5)
          ↓
    全连接层 (FC)
          ↓
      Sigmoid
          ↓
    输出: 0.92 (是水果)
```

### 关键参数

- **词汇表大小**: 100 个字符（包括 `<PAD>`, `<UNK>` 特殊标记）
- **嵌入维度**: 32
- **卷积核数量**: 64 个/尺度
- **卷积核大小**: [2, 3, 4] 个字符
- **Dropout**: 0.5 (防止过拟合)
- **优化器**: Adam (lr=0.001)
- **损失函数**: BCEWithLogitsLoss (带类别权重)

## 数据集

### 分类标准说明

本项目面临一个问题：**"水果"该如何定义？**

#### 两种分类标准

**日常分类** （基于风味和用途）
- 番茄是蔬菜，核桃是坚果，玉米是粮食
- 问题：不同文化和地域有差异

**植物学分类** （基于解剖结构）
- 果实 = 由花的子房发育、包裹种子的器官
- 番茄、核桃、玉米都是果实
- 优势：科学严谨、全球统一

#### 本项目的选择

我选择了植物学标准。虽然"水果"是日常俗称，但为了避免歧义，将**"果实"等同于"水果"**进行标注。

**简单理解**：
- ✅ 果实（由子房发育）= 标为"水果"
- ❌ 非果实（根、茎、叶等）= 标为"非水果"

### 数据规模

- 总样本: 1051 条
- 水果（果实）: 365 条
- 非水果（非果实）: 686 条

## 快速开始

### 1. 创建虚拟环境并安装依赖

```bash
# 创建虚拟环境
python -m venv venv

# 激活虚拟环境 (Windows)
venv\Scripts\activate

# 激活虚拟环境 (Linux/Mac)
source venv/bin/activate

# 安装依赖
pip install -r requirements.txt
```

### 2. 训练模型

```bash
python train.py
```

训练过程会：
- 自动构建字符词典
- 训练 50 个 epoch
- 每 5 个 epoch 显示进度
- 保存最佳模型到 `best_model.pth`
- 保存训练历史到 `history.json`

### 3. 可视化训练过程

```bash
python visualize.py
```

会生成 `training_curves.png`，包含：
- 训练/验证损失曲线
- 训练/验证准确率曲线

### 4. 预测新词语

```bash
python predict.py
```

支持：
- 批量测试内置样例
- 交互式输入预测

## 模型性能

相比第一个项目（逻辑回归）：

| 指标 | LR(323) | CNN迭1(323) | CNN迭2(826) | LR(826) | CNN调参(826) | LR(1051) | CNN迭4(1051) |
|------|---------|------------|------------|---------|-------------|---------|-------------|
| 验证准确率 | 80.00% | 69.23% | 66.27% | 81.33% | 66.87% | **86.26%** ✨ | 59.24% ❌ |
| 非水果精确率 | 84% | 75% | 73% | 82% | 73% | **91%** ✨ | 71% |
| 非水果召回率 | 62% | 38% | 73% | 90% | 73% | **88%** ✨ | 64% |
| 水果精确率 | - | 62% | 54% | 80% | 53% | **78%** | 42% ❌ |
| 水果召回率 | - | 69% | 54% | 66% | 52% | **84%** ✨ | 49% ❌ |
| 模型参数量 | ~25K | ~15K | ~22K | ~25K | ~11K | ~25K | ~22K |

**结论**:
1. **逻辑回归持续受益**: 随数据增加从80% → 81% → **86%**，稳步提升
2. **CNN反而下降**: 从66.27% → **59.24%**，下降7个百分点
3. **学术名词的影响**: 植物学术语增加了任务复杂度，CNN字符模式学习失效
4. **最终差距**: 逻辑回归86.26% vs CNN 59.24%，差距扩大到**27%**
5. **结论**: 在此任务上CNN完全不适合，逻辑回归是最优选择

## 项目结构

```
02-fruit-classifier-cnn/
├── venv/                    # 虚拟环境（需自行创建）
├── data.csv                 # 数据集（826条，扩充后）
├── train.py                 # CNN训练脚本
├── train_lr.py              # 逻辑回归训练脚本（对比用）
├── tune_hyperparameters.py  # CNN超参数调优脚本
├── predict.py               # CNN预测脚本
├── visualize.py             # 可视化脚本
├── requirements.txt         # 依赖列表
├── best_model.pth           # CNN最佳模型（训练后生成）
├── model_lr.joblib          # 逻辑回归模型（训练后生成）
├── char_vocab.json          # 字符词典（训练后生成）
├── vectorizer_lr.joblib     # 特征提取器（训练后生成）
├── history.json             # 训练历史（训练后生成）
├── tuning_results.csv       # 调参结果（调参后生成）
└── training_curves.png      # 训练曲线图（可视化后生成）
```

## 学到的核心概念

### 1. 字符嵌入（Character Embedding）
将离散的字符映射到连续的向量空间：
```
"草" → [0.12, -0.45, 0.78, ..., 0.23]  (32维向量)
"莓" → [-0.34, 0.67, -0.12, ..., 0.56]
```

### 2. 1D 卷积（Conv1D）
在字符序列上滑动窗口，提取局部特征：
```
输入: "草莓"
2-gram 卷积: ["草莓"]
3-gram 卷积: 无法应用（序列太短）
```

### 3. 多尺度卷积
同时使用多个卷积核大小：
- **2-gram**: 捕捉两字组合（"草莓"、"水果"）
- **3-gram**: 捕捉三字组合（"猕猴桃"）
- **4-gram**: 捕捉四字组合（"火龙果"）

### 4. 最大池化（Max Pooling）
从卷积结果中提取最重要的特征（最大值）

### 5. 防止过拟合的技巧
- **Dropout (0.5)**: 训练时随机丢弃 50% 的神经元
- **类别权重**: 自动平衡类别不平衡问题
- **早停（Early Stopping）**: 保存验证集上最佳的模型

## 与第一个项目的对比

| 维度 | 逻辑回归（项目01） | 字符级 CNN（项目02） |
|-----|------------------|-------------------|
| **模型类型** | 传统机器学习 | 深度学习 |
| **特征提取** | 手工设计（n-gram） | 自动学习（卷积） |
| **参数量** | ~25K | ~15K |
| **训练时间** | 秒级 | 分钟级 |
| **可解释性** | 高 | 低 |
| **效果** | 基准 | 更强 |
| **依赖** | scikit-learn | PyTorch |

## 可能遇到的问题

### Q: 为什么不用 BERT？
A: BERT 需要上下文，而我们的任务是单个词语分类，且数据量小（323条）。字符级 CNN 更适合这个场景。

### Q: 训练很慢怎么办？
A:
- 检查是否安装了 GPU 版本的 PyTorch
- 减少 `num_epochs`（从 50 减到 20）
- 减少 `num_filters`（从 64 减到 32）

### Q: 模型过拟合怎么办？
A:
- 增大 `dropout`（从 0.5 到 0.6）
- 减少 `num_filters`（从 64 到 32）
- 减少 `embedding_dim`（从 32 到 16）
- 增加数据量

### Q: 准确率没有提升？
A:
- 数据量本身较小（323条），深度学习优势有限
- 可以尝试收集更多数据
- 逻辑回归在小数据集上可能更稳定

## 迭代记录与学习笔记

### 📝 迭代 1: 首次训练（323条数据）

**结果**: 验证准确率 69.23%

**问题**: 效果反而不如项目01的逻辑回归（80%）

**原因分析**:
1. **数据量太小**：深度学习需要更多数据才能发挥优势
2. **逻辑回归更稳定**：在小数据集上，传统ML往往更可靠
3. **任务相对简单**：字符级n-gram特征已经足够

**收获**:
- 不要盲目追求"深度学习"
- 要根据数据量选择合适的模型
- 传统ML在小数据场景下仍有价值

---

### 📝 迭代 2: 数据扩充（826条数据）

**问题**: "水果"定义不清（番茄是蔬菜还是水果？核桃算不算？）

**解决**: 采用植物学标准（果实 = 由子房发育），将"果实"等同于"水果"

**结果**: 验证准确率 66.27%

**现象分析**:
1. **准确率略降**：69.23% → 66.27%（下降3%）
2. **模型更均衡**：非水果召回率 38% → 73%（大幅提升）
3. **仍不如传统ML**：CNN 66.27% vs 逻辑回归 80%

**收获**:
- 数据标注需要明确统一的标准
- 更多数据 ≠ 更好效果（标注质量同样重要）
- 小数据集（<1000条）深度学习优势难以体现
- 模型均衡性比单纯追求准确率更重要

**对比实验**: 用逻辑回归跑同样的826条数据
- 验证准确率: **81.33%** (vs CNN 66.27%)
- 非水果召回率: **90%** (vs CNN 73%)
- 水果精确率: **80%** (vs CNN 54%)
- **结论**: 传统ML在小数据场景下依然强于深度学习

---

### 📝 迭代 3: CNN超参数调优

**动机**: CNN效果不如逻辑回归,尝试通过调参优化

**方法**:
- 搜索空间: embedding_dim[16,32,64], num_filters[32,64,128], dropout[0.3,0.5,0.7], lr[0.0005,0.001,0.002], batch_size[16,32,64]
- 随机采样20组参数组合
- 早停策略: patience=10

**结果**:
- 最佳准确率: **66.87%** (baseline 66.27%, 提升仅0.6%)
- 最佳参数: emb=16, filters=32, drop=0.3, lr=0.002, batch=16

**结论**:
- **调参收益极小**: 20组参数全在64.5%-66.9%区间
- **遇到性能天花板**: 数据量太小导致CNN无法学习有效特征
- **仍远低于逻辑回归**: 66.87% vs 81.33% (差距14.5%)
- **最终认知**: 小数据场景(<1000条)深度学习很难超越传统ML

---

### 📝 迭代 4: 扩大数据集至1051条

**动机**: 测试更多数据是否能缩小CNN与逻辑回归的差距

**扩充策略**:
- 植物学术语: 子房、胚珠、花被、果皮、种皮等 (非水果)
- 植物分类: 被子植物、裸子植物、单子叶、双子叶、科属名 (非水果)
- 果实类型: 浆果、核果、坚果、蒴果、荚果等 (水果)
- 谷物豆类: 小麦、水稻、大豆、红豆、绿豆等 (水果-植物学果实)
- 更多蔬菜: 生姜、大蒜、芹菜、菠菜等 (非水果)
- 相关器具: 水果刀、榨汁机、果园等 (非水果)
- 加工制品: 果脯、蜜饯、果酱等 (非水果-已失去果实属性)

**数据规模**: 从826条 → 1051条 (+225条, +27%)

**结果对比**:

| 模型 | 826条准确率 | 1051条准确率 | 变化 |
|------|-----------|------------|------|
| 逻辑回归 | 81.33% | **86.26%** | ✅ +4.93% |
| CNN | 66.27% | **59.24%** | ❌ -7.03% |

**现象分析**:
1. **逻辑回归受益**: 更多数据帮助n-gram特征更稳定，准确率稳步提升
2. **CNN严重退步**: 学术名词字符模式复杂，小模型无法泛化
3. **差距扩大**: 从14.5% → **27%**，CNN彻底失败

**深层原因**:
- **字符级CNN的局限**: "子房"、"花被"等术语字符与水果名重叠，模式混乱
- **数据量仍不足**: 1051条对CNN学习复杂模式远远不够
- **任务不匹配**: 短文本分类更适合n-gram特征，不适合深度特征

**最终结论**:
- 在此任务上，**CNN完全不适合**，无论如何调整都无法超越逻辑回归
- 逻辑回归是最优选择，简单、快速、有效
- **不要为了用深度学习而用深度学习**，合适的工具更重要

---

## 项目总结

### 🎯 核心收获

虽然CNN在此任务上完全失败，但这个项目**并非浪费时间**，反而收获巨大：

#### 1. 技术层面的学习
- ✅ **掌握了字符级CNN**: 完整实现了embedding → 多尺度卷积 → 池化 → 分类的pipeline
- ✅ **PyTorch实践经验**: 从模型定义、训练循环、模型保存到可视化的完整流程
- ✅ **超参数调优**: 理解了网格搜索、早停、学习率等概念
- ✅ **深度学习调试**: 学会分析训练曲线、混淆矩阵，诊断模型问题

#### 2. 认知层面的提升
- 💡 **模型选择比技术先进更重要**: 不是所有问题都需要深度学习
- 💡 **数据量决定模型上限**: 小数据(<1000条)传统ML往往更优
- 💡 **任务匹配很关键**: 短文本分类本质上更适合n-gram特征
- 💡 **失败也是宝贵经验**: 通过对比实验深刻理解了不同方法的适用场景

#### 3. 科学实验精神
- 🔬 **完整的对比实验**: 4次迭代，系统性地测试了不同数据量和参数配置
- 🔬 **诚实记录失败**: 没有隐藏CNN失败的事实，真实展示学习过程
- 🔬 **数据驱动决策**: 用数据说话，而非盲目相信"深度学习更强"

### 📊 最终结论

| 维度 | 逻辑回归 | 字符级CNN |
|-----|---------|----------|
| **准确率** | 86.26% ✨ | 59.24% |
| **训练速度** | 秒级 | 分钟级 |
| **可解释性** | 高 | 低 |
| **代码复杂度** | 简单 | 复杂 |
| **依赖** | sklearn | PyTorch |
| **适用场景** | ✅ 此任务完美 | ❌ 需大量数据 |

### 💡 关键启示

> **并非所有问题都需要深度学习，选择合适的工具才是关键！**

这个项目最大的价值在于：
1. **打破了"深度学习万能"的迷思**
2. **建立了"具体问题具体分析"的思维**
3. **获得了完整的深度学习实践经验**
4. **学会了通过实验验证假设**

**如果一开始就选逻辑回归，虽然效果好，但不会有这些深刻的认知。**

---

## 下一步改进方向

虽然此任务不适合CNN，但在其他场景下可以尝试：

1. **长文本分类**: 字符级CNN在长文本(>100字)上可能更有优势
2. **多语言场景**: 不需要分词的优势在多语言混合时更明显
3. **大规模数据**: 当数据量>10万时，深度学习优势才能体现
4. **迁移学习**: 使用预训练模型（如BERT）而非从零训练
5. **其他任务**: 情感分析、垃圾邮件检测等可能更适合CNN

## 参考资料

- [Character-level Convolutional Networks for Text Classification](https://arxiv.org/abs/1509.01626)
- [PyTorch 官方教程](https://pytorch.org/tutorials/)
- [Text Classification with CNN](https://www.aclweb.org/anthology/D14-1181.pdf)

## License

MIT
